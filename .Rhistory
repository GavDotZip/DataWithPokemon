complaints <- read.csv("C:/Users/gavin/PycharmProjects/ConsumerBehaviour/src/data/complaints.csv")
# Remove rows with any NA values
complaints_clean <- na.omit(complaints)
# Check the structure of the cleaned dataset
str(complaints_clean)
write.csv(complaints_clean, file = "C:/Users/gavin/PycharmProjects/ConsumerBehaviour/src/data/complaints_clean.csv", row.names = FALSE)
# Load the required library for data manipulation
library(dplyr)
# Load the required library for data manipulation
library(dplyr)
# Read the CSV file into a dataframe
data <- read.csv("C:\Users\gavin\PycharmProjects\ConsumerBehaviour\src\data\Amazon_Customer_Behavior_Survey.csv")
# Load the required library for data manipulation
library(dplyr)
# Read the CSV file into a dataframe
data <- read.csv("C:/Users/gavin/PycharmProjects/ConsumerBehaviour/src/data/Amazon_Customer_Behavior_Survey.csv")
# View the structure of the dataframe
str(data)
# Dataset downloaded from https://www.kaggle.com/datasets/swathiunnikrishnan/amazon-consumer-behaviour-dataset/data
# Load the required library for data manipulation
library(dplyr)
# Read the CSV file into a dataframe
amazon <- read.csv("C:/Users/gavin/PycharmProjects/ConsumerBehaviour/src/data/Amazon_Customer_Behavior_Survey.csv")
# View the structure of the dataframe
str(amazon)
# Summary statistics for numerical variables
summary(amazon$age)  # Summary statistics for age
# Frequency table for categorical variables
table(amazon$gender)  # Frequency table for gender
# Mean purchase frequency
mean(amazon$Purchase_Frequency)  # Assuming Purchase_Frequency is encoded as numeric
# Proportion of customers who leave reviews
prop.table(table(amazon$Review_Left))
# Average shopping satisfaction by gender
amazon %>%
group_by(gender) %>%
summarise(avg_satisfaction = mean(Shopping_Satisfaction))
# Dataset downloaded from https://www.kaggle.com/datasets/swathiunnikrishnan/amazon-consumer-behaviour-dataset/data
# Load the required library for data manipulation
library(dplyr)
# Average shopping satisfaction by gender
amazon %>%
group_by(gender) %>%
summarise(avg_satisfaction = mean(Shopping_Satisfaction))
# Average shopping satisfaction by gender
amazon %>%
group_by(Gender) %>%
summarise(avg_satisfaction = mean(Shopping_Satisfaction))
# View the structure of the dataframe
str(amazon)
# Summary statistics for numerical variables
summary(amazon$age)  # Summary statistics for age
# Frequency table for categorical variables
table(amazon$Gender)  # Frequency table for gender
# Mean purchase frequency
mean(amazon$Purchase_Frequency)  # Assuming Purchase_Frequency is encoded as numeric
# Convert Purchase_Frequency to numeric representation
amazon <- amazon %>%
mutate(Purchase_Frequency_Numeric = case_when(
Purchase_Frequency == "Weekly" ~ 7,
Purchase_Frequency == "Bi-weekly" ~ 14,
Purchase_Frequency == "Monthly" ~ 30,
# Add more cases for other frequencies as needed
TRUE ~ as.numeric(Purchase_Frequency)  # For any other values (e.g., if already numeric)
))
# Calculate the mean purchase frequency
mean_purchase_frequency <- mean(amazon$Purchase_Frequency_Numeric, na.rm = TRUE)
print(mean_purchase_frequency)
# Dataset downloaded from https://www.kaggle.com/datasets/swathiunnikrishnan/amazon-consumer-behaviour-dataset/data
# Load the required library for data manipulation
library(dplyr)
# Read the CSV file into a dataframe
amazon <- read.csv("C:/Users/gavin/PycharmProjects/ConsumerBehaviour/src/data/Amazon_Customer_Behavior_Survey.csv")
# View the structure of the dataframe
str(amazon)
# Dataset downloaded from https://www.kaggle.com/datasets/swathiunnikrishnan/amazon-consumer-behaviour-dataset/data
# Load the required library for data manipulation
library(dplyr)
# Read the CSV file into a dataframe
amazon <- read.csv("C:\Users\gavin\Downloads\Amazon_Customer_Behavior_Survey.csv")
# Read the CSV file into a dataframe
amazon <- read.csv("C:/Users/gavin/Downloads/Amazon_Customer_Behavior_Survey.csv")
# View the structure of the dataframe
str(amazon)
# Summary statistics for numerical variables
summary(amazon$age)  # Summary statistics for age
# Frequency table for categorical variables
table(amazon$Gender)  # Frequency table for gender
# Proportion of customers who leave reviews
prop.table(table(amazon$Review_Left))
# Average shopping satisfaction by gender
amazon %>%
group_by(Gender) %>%
summarise(avg_satisfaction = mean(Shopping_Satisfaction))
# Correlation between variables
cor(amazon$age, amazon$Shopping_Satisfaction)
# Bar plot of Purchase Categories
library(ggplot2)
ggplot(amazon, aes(x = Purchase_Categories)) +
geom_bar() +
labs(title = "Purchase Categories", x = "Category", y = "Count")
# Calculate frequency of each purchase category
category_counts <- amazon %>%
count(Purchase_Categories) %>%
arrange(desc(n))  # Arrange in descending order of frequency
# Select top 5 categories
top_5_categories <- head(category_counts$Purchase_Categories, 5)
# Filter data for only the top 5 categories
amazon_top_5 <- amazon %>%
filter(Purchase_Categories %in% top_5_categories)
# Plot the bar chart for top 5 categories
ggplot(amazon_top_5, aes(x = Purchase_Categories)) +
geom_bar() +
labs(title = "Top 5 Purchase Categories", x = "Category", y = "Count")
# Box plot of Age by Gender
ggplot(amazon, aes(x = gender, y = age)) +
geom_boxplot() +
labs(title = "Age Distribution by Gender", x = "Gender", y = "Age")
# Box plot of Age by Gender
ggplot(amazon, aes(x = Gender, y = age)) +
geom_boxplot() +
labs(title = "Age Distribution by Gender", x = "Gender", y = "Age")
# Scatter plot of Age vs. Shopping Satisfaction
ggplot(amazon, aes(x = age, y = Shopping_Satisfaction)) +
geom_point() +
labs(title = "Age vs. Shopping Satisfaction", x = "Age", y = "Shopping Satisfaction")
# Classification of Gender and Purchase Frequency
# Preprocess the data
# Convert categorical variables to factors
amazon$gender <- as.factor(amazon$gender)
# Classification of Gender and Purchase Frequency
# Preprocess the data
# Convert categorical variables to factors
amazon$Gender <- as.factor(amazon$Gender)
amazon$Purchase_Frequency <- as.factor(amazon$Purchase_Frequency)
# Convert "Review_Left" to a factor (the target variable)
amazon$Review_Left <- as.factor(amazon$Review_Left)
# Split the data into training and testing sets
set.seed(123)  # Set seed for reproducibility
train_index <- createDataPartition(amazon$Review_Left, p = 0.7, list = FALSE)
# Classification of Gender and Purchase Frequency
library(caret)
install.packages("caret")
# Classification of Gender and Purchase Frequency
library(caret)
# Split the data into training and testing sets
set.seed(123)  # Set seed for reproducibility
train_index <- createDataPartition(amazon$Review_Left, p = 0.7, list = FALSE)
train_data <- amazon[train_index, ]
test_data <- amazon[-train_index, ]
# Build a logistic regression model
model <- glm(Review_Left ~ ., data = train_data, family = "binomial")
# Make predictions on the test set
predictions <- predict(model, newdata = test_data, type = "response")
# Convert probabilities to class labels (0 or 1)
predicted_classes <- ifelse(predictions > 0.5, 1, 0)
# Evaluate the model
confusion_matrix <- confusionMatrix(as.factor(predicted_classes), as.factor(test_data$Review_Left))
print(confusion_matrix)
# Preprocess the data
# Convert categorical variables to factors
amazon$Gender <- as.factor(amazon$Gender)
amazon$Purchase_Frequency <- as.factor(amazon$Purchase_Frequency)
# Convert "Review_Left" to a factor (the target variable)
amazon$Review_Left <- as.factor(amazon$Review_Left)
# Split the data into training and testing sets
set.seed(123)  # Set seed for reproducibility
train_index <- createDataPartition(amazon$Review_Left, p = 0.7, list = FALSE)
train_data <- amazon[train_index, ]
test_data <- amazon[-train_index, ]
# Split the data into training and testing sets
set.seed(123)  # Set seed for reproducibility
train_index <- createDataPartition(amazon$Review_Left, p = 0.7, list = FALSE)
# Dataset downloaded from https://www.kaggle.com/datasets/swathiunnikrishnan/amazon-consumer-behaviour-dataset/data
# Load the required library for data manipulation
library(dplyr)
# Read the CSV file into a dataframe
amazon <- read.csv("C:/Users/gavin/Downloads/Amazon_Customer_Behavior_Survey.csv")
# View the structure of the dataframe
str(amazon)
# Summary statistics for numerical variables
summary(amazon$age)  # Summary statistics for age
# Frequency table for categorical variables
table(amazon$Gender)  # Frequency table for gender
# Proportion of customers who leave reviews
prop.table(table(amazon$Review_Left))
# Average shopping satisfaction by gender
amazon %>%
group_by(Gender) %>%
summarise(avg_satisfaction = mean(Shopping_Satisfaction))
# Correlation between variables
cor(amazon$age, amazon$Shopping_Satisfaction)
# Bar plot of Top 5 Purchase Categories
library(ggplot2)
# Calculate frequency of each purchase category
category_counts <- amazon %>%
count(Purchase_Categories) %>%
arrange(desc(n))  # Arrange in descending order of frequency
# Select top 5 categories
top_5_categories <- head(category_counts$Purchase_Categories, 5)
# Filter data for only the top 5 categories
amazon_top_5 <- amazon %>%
filter(Purchase_Categories %in% top_5_categories)
# Plot the bar chart for top 5 categories
ggplot(amazon_top_5, aes(x = Purchase_Categories)) +
geom_bar() +
labs(title = "Top 5 Purchase Categories", x = "Category", y = "Count")
# Box plot of Age by Gender
ggplot(amazon, aes(x = Gender, y = age)) +
geom_boxplot() +
labs(title = "Age Distribution by Gender", x = "Gender", y = "Age")
# Scatter plot of Age vs. Shopping Satisfaction
ggplot(amazon, aes(x = age, y = Shopping_Satisfaction)) +
geom_point() +
labs(title = "Age vs. Shopping Satisfaction", x = "Age", y = "Shopping Satisfaction")
# Classification of Gender and Purchase Frequency
library(caret)
# Preprocess the data
# Convert categorical variables to factors
amazon$Gender <- as.factor(amazon$Gender)
amazon$Purchase_Frequency <- as.factor(amazon$Purchase_Frequency)
# Convert "Review_Left" to a factor (the target variable)
amazon$Review_Left <- as.factor(amazon$Review_Left)
# Split the data into training and testing sets
set.seed(123)  # Set seed for reproducibility
train_index <- createDataPartition(amazon$Review_Left, p = 0.7, list = FALSE)
train_data <- amazon[train_index, ]
test_data <- amazon[-train_index, ]
# Build a logistic regression model
model <- glm(Review_Left ~ ., data = train_data, family = "binomial")
# Build a logistic regression model
model <- glm(Review_Left ~ ., data = train_data, family = "binomial", maxit = 1000)
# Make predictions on the test set
predictions <- predict(model, newdata = test_data, type = "response")
# Convert Timestamp column to factors and ensure consistent levels in both datasets
amazon$Timestamp <- as.factor(amazon$Timestamp)
test_data$Timestamp <- factor(test_data$Timestamp, levels = levels(amazon$Timestamp))
# Make predictions on the test set
predictions <- predict(model, newdata = test_data, type = "response")
# Convert Timestamp column to factors in both datasets
train_data$Timestamp <- as.factor(train_data$Timestamp)
test_data$Timestamp <- as.factor(test_data$Timestamp)
# Ensure consistency of levels between train and test datasets
test_data$Timestamp <- factor(test_data$Timestamp, levels = levels(train_data$Timestamp))
# Make predictions on the test set
predictions <- predict(model, newdata = test_data, type = "response")
# Convert Service_Appreciation column to factors in both datasets
train_data$Service_Appreciation <- as.factor(train_data$Service_Appreciation)
test_data$Service_Appreciation <- as.factor(test_data$Service_Appreciation)
# Ensure consistency of levels between train and test datasets
test_data$Service_Appreciation <- factor(test_data$Service_Appreciation, levels = levels(train_data$Service_Appreciation))
# Make predictions on the test set
predictions <- predict(model, newdata = test_data, type = "response")
# Convert Improvement_Areas column to factors in both datasets
train_data$Improvement_Areas <- as.factor(train_data$Improvement_Areas)
test_data$Improvement_Areas <- as.factor(test_data$Improvement_Areas)
# Ensure consistency of levels between train and test datasets
test_data$Improvement_Areas <- factor(test_data$Improvement_Areas, levels = levels(train_data$Improvement_Areas))
# Make predictions on the test set
predictions <- predict(model, newdata = test_data, type = "response")
# Convert probabilities to class labels (0 or 1)
predicted_classes <- ifelse(predictions > 0.5, 1, 0)
# Evaluate the model
confusion_matrix <- confusionMatrix(as.factor(predicted_classes), as.factor(test_data$Review_Left))
# Convert both vectors to factors with the same levels
predicted_classes <- factor(predicted_classes, levels = levels(test_data$Review_Left))
# Create confusion matrix
confusion_matrix <- confusionMatrix(predicted_classes, test_data$Review_Left)
print(confusion_matrix)
tinytex::install_tinytex()
knitr::opts_chunk$set(echo = TRUE)
# Load required libraries
library(tidyverse)
# Read the dataset
suicide_data <- read_csv("C:/Users/gavin/Downloads/SuicideRates/age_std_suicide_rates_1990-2022.csv")
# Display the structure of the dataset
str(suicide_data)
# Load required libraries
library(tidyverse)
# Read the dataset
suicide_data <- read_csv("C:/Users/gavin/Downloads/SuicideRates/age_std_suicide_rates_1990-2022.csv")
# Display the structure of the dataset
str(suicide_data)
# Display the first few rows of the dataset
head(suicide_data)
# Summary statistics
summary(suicide_data)
# Check for missing values
colSums(is.na(suicide_data))
# Unique values in Sex column
unique(suicide_data$Sex)
# Unique values in Year column
unique(suicide_data$Year)
# Create a line chart of suicide rates over time
suicide_rates_over_time <- suicide_data %>%
group_by(Year) %>%
summarise(total_suicide_rate = sum(SuicideCount) / sum(Population) * 100000)  # Calculate suicide rate per 100,000 population
# Plot
ggplot(suicide_rates_over_time, aes(x = Year, y = total_suicide_rate)) +
geom_line(color = "skyblue", size = 1) +
geom_point(color = "blue", size = 2) +
labs(title = "Suicide Rates Over Time", x = "Year", y = "Suicide Rate per 100,000 Population") +
theme_minimal()
View(suicide_data)
View(suicide_data)
# Load required libraries
library(tidyverse)
# Read the dataset
suicide_data <- read_csv("C:/Users/gavin/Downloads/SuicideRates/age_std_suicide_rates_1990-2022.csv")
# Display the structure of the dataset
str(suicide_data)
# Display the first few rows of the dataset
head(suicide_data)
# Summary statistics
summary(suicide_data)
# Check for missing values
colSums(is.na(suicide_data))
# Unique values in Sex column
unique(suicide_data$Sex)
# Unique values in Year column
unique(suicide_data$Year)
# Check the data range of years available
unique_years <- unique(suicide_data$Year)
min_year <- min(unique_years)
max_year <- max(unique_years)
# Display unique years
unique_years
# Create a line chart of suicide rates over time
suicide_rates_over_time <- suicide_data %>%
group_by(Year) %>%
summarise(total_suicide_rate = sum(SuicideCount) / sum(Population) * 100000)  # Calculate suicide rate per 100,000 population
# Plot
ggplot(suicide_rates_over_time, aes(x = Year, y = total_suicide_rate)) +
geom_line(color = "skyblue", size = 1) +
geom_point(color = "blue", size = 2) +
labs(title = "Suicide Rates Over Time", x = "Year", y = "Suicide Rate per 100,000 Population") +
theme_minimal()
# Filter out rows with missing values in SuicideCount or Population
cleaned_data <- suicide_data %>%
filter(!is.na(SuicideCount) & !is.na(Population))
# Create a line chart of suicide rates over time
suicide_rates_over_time <- cleaned_data %>%
group_by(Year) %>%
summarise(total_suicide_rate = sum(SuicideCount) / sum(Population) * 100000)  # Calculate suicide rate per 100,000 population
# Plot
ggplot(suicide_rates_over_time, aes(x = Year, y = total_suicide_rate)) +
geom_line(color = "skyblue", size = 1) +
geom_point(color = "blue", size = 2) +
labs(title = "Suicide Rates Over Time", x = "Year", y = "Suicide Rate per 100,000 Population") +
theme_minimal()
View(cleaned_data)
unique(suicide_data$CountryName)
# Calculate suicide rates per 100,000 population by gender
suicide_rates_by_gender <- suicide_data %>%
group_by(Sex, Year) %>%
summarise(total_suicide_rate = sum(SuicideCount) / sum(Population) * 100000)
# Plot
ggplot(suicide_rates_by_gender, aes(x = Sex, y = total_suicide_rate, fill = Sex)) +
geom_boxplot() +
labs(title = "Suicide Rates by Gender", x = "Gender", y = "Suicide Rate per 100,000 Population") +
theme_minimal()
# Filter out rows with non-finite values in total_suicide_rate
cleaned_data <- suicide_rates_by_gender %>%
filter(!is.na(total_suicide_rate) & is.finite(total_suicide_rate))
# Plot
ggplot(cleaned_data, aes(x = Sex, y = total_suicide_rate, fill = Sex)) +
geom_boxplot() +
labs(title = "Suicide Rates by Gender", x = "Gender", y = "Suicide Rate per 100,000 Population") +
theme_minimal()
# Plot
ggplot(cleaned_data, aes(x = Sex, y = total_suicide_rate, fill = Sex)) +
geom_barplot() +
labs(title = "Suicide Rates by Gender", x = "Gender", y = "Suicide Rate per 100,000 Population") +
theme_minimal()
# Plot
ggplot(cleaned_data, aes(x = Sex, y = total_suicide_rate, fill = Sex)) +
geom_barchart() +
labs(title = "Suicide Rates by Gender", x = "Gender", y = "Suicide Rate per 100,000 Population") +
theme_minimal()
# Plot
ggplot(cleaned_data, aes(x = Sex, y = total_suicide_rate, fill = Sex)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Suicide Rates by Gender", x = "Gender", y = "Suicide Rate per 100,000 Population") +
theme_minimal()
# Calculate suicide rates per 100,000 population by age group and year
suicide_rates_by_age <- suicide_data %>%
group_by(Year, AgeGroup) %>%
summarise(total_suicide_rate = sum(SuicideCount) / sum(Population) * 100000)
# Plot
ggplot(suicide_rates_by_age, aes(x = Year, y = total_suicide_rate, color = AgeGroup)) +
geom_line() +
labs(title = "Trend Analysis of Suicide Rates by Age Group Over Time",
x = "Year", y = "Suicide Rate per 100,000 Population",
color = "Age Group") +
theme_minimal()
View(suicide_data)
rlang::last_trace()
# Create age groups
suicide_data <- suicide_data %>%
mutate(AgeGroup = cut(Age, breaks = c(0, 18, 30, 45, 60, Inf),
labels = c("0-18", "19-30", "31-45", "46-60", "61+")))
# Calculate suicide rates per 100,000 population by age group and year
suicide_rates_by_age <- suicide_data %>%
group_by(Year, AgeGroup) %>%
summarise(total_suicide_rate = sum(SuicideCount) / sum(Population) * 100000)
# Plot
ggplot(suicide_rates_by_age, aes(x = Year, y = total_suicide_rate, color = AgeGroup)) +
geom_line() +
labs(title = "Trend Analysis of Suicide Rates by Age Group Over Time",
x = "Year", y = "Suicide Rate per 100,000 Population",
color = "Age Group") +
theme_minimal()
View(suicide_rates_over_time)
# Calculate suicide rates per 100,000 population by area type and year
suicide_rates_by_area <- suicide_data %>%
group_by(Year, AreaType) %>%
summarise(total_suicide_rate = sum(SuicideCount) / sum(Population) * 100000)
# Plot
ggplot(suicide_rates_by_area, aes(x = Year, y = total_suicide_rate, fill = AreaType)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Comparison of Suicide Rates between Urban and Rural Areas",
x = "Year", y = "Suicide Rate per 100,000 Population",
fill = "Area Type") +
theme_minimal()
# Calculate suicide rates per 100,000 population by region and year
suicide_rates_by_region <- suicide_data %>%
group_by(Year, RegionName) %>%
summarise(total_suicide_rate = sum(SuicideCount) / sum(Population) * 100000)
# Plot
ggplot(suicide_rates_by_region, aes(x = Year, y = total_suicide_rate, color = RegionName)) +
geom_line() +
labs(title = "Suicide Rates by Region Over Time",
x = "Year", y = "Suicide Rate per 100,000 Population",
color = "Region") +
theme_minimal()
# Calculate suicide rates per 100,000 population by region and year
suicide_rates_by_region <- suicide_data %>%
group_by(Year, RegionName) %>%
summarise(total_suicide_rate = sum(SuicideCount) / sum(Population) * 100000)
# Plot
ggplot(suicide_rates_by_region, aes(x = Year, y = total_suicide_rate, color = RegionName)) +
geom_line() +
labs(title = "Suicide Rates by Region Over Time",
x = "Year", y = "Suicide Rate per 100,000 Population",
color = "Region") +
theme_minimal()
# Filter out rows with missing values in total_suicide_rate
cleaned_data <- suicide_rates_by_region %>%
filter(!is.na(total_suicide_rate))
# Plot
ggplot(cleaned_data, aes(x = Year, y = total_suicide_rate, color = RegionName)) +
geom_line() +
labs(title = "Suicide Rates by Region Over Time",
x = "Year", y = "Suicide Rate per 100,000 Population",
color = "Region") +
theme_minimal()
# Calculate suicide rates per 100,000 population by area type and year
suicide_rates_by_area <- suicide_data %>%
group_by(Year, AreaType) %>%
summarise(total_suicide_rate = sum(SuicideCount) / sum(Population) * 100000)
# Plot
ggplot(suicide_rates_by_area, aes(x = Year, y = total_suicide_rate, fill = AreaType)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Comparison of Suicide Rates between Urban and Rural Areas",
x = "Year", y = "Suicide Rate per 100,000 Population",
fill = "Area Type") +
theme_minimal()
## Specialized Analysis 2: Comparison of Suicide Rates between Urban and Rural Areas
library(ggplot2)
# Calculate suicide rates per 100,000 population by area type and year
suicide_rates_by_area <- suicide_data %>%
group_by(Year, AreaType) %>%
summarise(total_suicide_rate = sum(SuicideCount) / sum(Population) * 100000)
library(dplyr)
# Calculate suicide rates per 100,000 population by area type and year
suicide_rates_by_area <- suicide_data %>%
group_by(Year, AreaType) %>%
summarise(total_suicide_rate = sum(SuicideCount) / sum(Population) * 100000)
# Plot
ggplot(suicide_rates_by_area, aes(x = Year, y = total_suicide_rate, fill = AreaType)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Comparison of Suicide Rates between Urban and Rural Areas",
x = "Year", y = "Suicide Rate per 100,000 Population",
fill = "Area Type") +
theme_minimal()
# Calculate suicide rates per 100,000 population by area type and year
suicide_rates_by_area <- suicide_data %>%
group_by(Year, AreaType) %>%
summarise(total_suicide_rate = sum(SuicideCount) / sum(Region) * 100000)
# Plot
ggplot(suicide_rates_by_area, aes(x = Year, y = total_suicide_rate, fill = AreaType)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Comparison of Suicide Rates between Urban and Rural Areas",
x = "Year", y = "Suicide Rate per 100,000 Population",
fill = "Area Type") +
theme_minimal()
# Select relevant columns for correlation analysis
economic_data <- select(suicide_data, Year, SuicideCount, Population, GDP, GDPPerCapita, GNI, GNIPerCapita)
# Calculate correlation matrix
correlation_matrix <- cor(economic_data, use = "complete.obs")
# Plot correlation matrix
corrplot(correlation_matrix, method = "color", type = "upper", order = "hclust",
addrect = 4, tl.cex = 0.7, title = "Correlation Matrix: Suicide Rates and Economic Indicators")
## Specialized Analysis 2: Correlation Analysis between Suicide Rates and Economic Indicators
library(corrplot)
# Select relevant columns for correlation analysis
economic_data <- select(suicide_data, Year, SuicideCount, Population, GDP, GDPPerCapita, GNI, GNIPerCapita)
# Calculate correlation matrix
correlation_matrix <- cor(economic_data, use = "complete.obs")
# Plot correlation matrix
corrplot(correlation_matrix, method = "color", type = "upper", order = "hclust",
addrect = 4, tl.cex = 0.7, title = "Correlation Matrix: Suicide Rates and Economic Indicators")
